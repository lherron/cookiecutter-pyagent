This file is a merged representation of a subset of the codebase, containing files not matching ignore patterns, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching these patterns are excluded: uv.lock
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

<additional_info>

</additional_info>

</file_summary>

<directory_structure>
{{cookiecutter.project_name}}/
  .github/
    ISSUE_TEMPLATE.md
  docs/
  scripts/
    run_{{cookiecutter.project_slug}}.py
  src/
    {{cookiecutter.project_slug}}/
      cli/
        __init__.py
        cli.py
      flows/
        __init__.py
        {{cookiecutter.project_slug}}_flow.py
      util/
        __init__.py
        llm.py
        todoist.py
      __init__.py
      {{cookiecutter.project_slug}}.py
      config.py
  tests/
    __init__.py
    test_{{cookiecutter.project_slug}}.py
  .gitignore
  pyproject.toml
  README.md
.gitignore
.repomixignore
cookiecutter.json
Makefile
test_config.json
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".repomixignore">
**/spec-*.txt
samples/**
simple-calculator/**
</file>

<file path="{{cookiecutter.project_name}}/.github/ISSUE_TEMPLATE.md">
* {{ cookiecutter.project_name }} version:
* Python version:
* Operating System:

### Description

Describe what you were trying to get done.
Tell us what happened, what went wrong, and what you expected to happen.

### What I Did

```
Paste the command(s) you ran and the output.
If there was a crash, please include the traceback here.
```
</file>

<file path="{{cookiecutter.project_name}}/src/{{cookiecutter.project_slug}}/cli/__init__.py">
"""
CLI package for {{cookiecutter.project_name}}.
"""
</file>

<file path="{{cookiecutter.project_name}}/src/{{cookiecutter.project_slug}}/cli/cli.py">
"""
Command line interface for {{cookiecutter.project_name}}.
"""

import logging
import sys
import asyncio
import os
from typing import Optional
import yaml
from datetime import timedelta
from functools import partial
from prefect.schedules import Interval
from prefect import serve, flow
from prefect import flow


import typer

from {{cookiecutter.project_slug}}.flows.{{cookiecutter.project_slug}}_flow import {{cookiecutter.project_slug}}_flow
from {{cookiecutter.project_slug}}.config import load_config, AppConfig
# Note: Assuming register_flow_schedule is defined elsewhere or needs implementation
# from {{cookiecutter.project_slug}}.flows.registration import register_flow_schedule 

# Set up logging
logging.basicConfig(
    level=logging.DEBUG,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

app = typer.Typer(help="{{cookiecutter.project_name}} CLI")

# Placeholder for the registration function if not defined elsewhere
# def register_flow_schedule(config_path: Optional[str] = None):
#    logger.warning(f"Placeholder function called for register_flow_schedule with config: {config_path}")
#    # Implement actual registration logic here
#    pass

@app.command()
def run(
    config: Optional[str] = typer.Option(None, "--config", "-c", help="Path to configuration file")
):
    """
    Run the {{cookiecutter.project_slug}} flow.
    """
    logger.info("Running {{cookiecutter.project_slug}} flow")
    # Typer handles running async functions
    async def run_flow_async(config_path: Optional[str] = None):
        """Run the {{cookiecutter.project_slug}} flow asynchronously."""
        await {{cookiecutter.project_slug}}_flow(config_path=config_path)

    asyncio.run(run_flow_async(config_path=config))


@app.command()
def schedule(
    config: Optional[str] = typer.Option(None, "--config", "-c", help="Path to configuration file. If not provided, attempts to load 'config.yaml'.")
):
    """
    Schedule the {{cookiecutter.project_slug}}_flow based on config.
    """
    logger.info("Scheduling flow")
    config_path = config if config else "config.yaml"  # Determine potential config path

    try:
        # Load configuration
        if config and os.path.exists(config_path):
            # If a specific config path was provided and exists, load it
            logger.debug(f"Loading configuration from provided path: {config_path}")
            app_config: AppConfig = load_config(config_path=config_path)
            effective_config_path = config_path # Use the provided path
        elif not config and os.path.exists(config_path):
            # If no config path provided, but default 'config.yaml' exists, load it
            logger.debug(f"Loading configuration from default path: {config_path}")
            app_config: AppConfig = load_config(config_path=config_path)
            effective_config_path = config_path # Use the default path
        else:
            # If path doesn't exist (or wasn't provided and default doesn't exist)
            if config:
                 logger.warning(f"Configuration file specified at '{config_path}' not found. Attempting to load default configuration.")
            else:
                 logger.info(f"Default configuration file '{config_path}' not found. Attempting to load default configuration settings.")
            app_config: AppConfig = load_config() # Call without arguments
            effective_config_path = None # No specific config file used for schedule

        logger.debug("Configuration loaded successfully.")

        {{cookiecutter.project_slug}}_flow.serve(name="flowing", cron="* * * * *")
    except Exception as e:
        logger.error(f"An unexpected error occurred during scheduling: {e}")
        # logger.exception("Detailed error:") # Uncomment for detailed traceback
        raise typer.Exit(code=1)

    # TODO: Implement the schedule logic here


def main():
    """Main entry point for the CLI."""
    # Typer handles command parsing and execution
    app()

if __name__ == "__main__":
    main()
</file>

<file path="{{cookiecutter.project_name}}/src/{{cookiecutter.project_slug}}/flows/__init__.py">
"""
Flows module for todoist-ideation-agent.
"""

from .{{cookiecutter.project_slug}}_flow import {{cookiecutter.project_slug}}_flow

__all__ = ["{{cookiecutter.project_slug}}_flow"]
</file>

<file path="{{cookiecutter.project_name}}/src/{{cookiecutter.project_slug}}/flows/{{cookiecutter.project_slug}}_flow.py">
"""
Generic Prefect flow for {{cookiecutter.project_name}}.
This serves as a template for creating specific flows.
"""

from prefect import flow, task, get_run_logger
from typing import Optional
import logging
from datetime import timedelta, datetime
import time
from prefect.schedules import Interval

# Assuming a basic config structure might exist, adjust as needed
# from ..config import load_config, AppConfig

# Set up logging
logger = logging.getLogger(__name__)

# Function to configure Prefect logging handler
def configure_prefect_logging():
    prefect_logger = get_run_logger()

    class PrefectHandler(logging.Handler):
        def emit(self, record):
            log_method_name = record.levelname.lower()
            if log_method_name == "warning":
                log_method_name = "warn"
            log_method = getattr(prefect_logger, log_method_name, prefect_logger.info)
            log_method(self.format(record))

    formatter = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")
    handler = PrefectHandler()
    handler.setFormatter(formatter)

    flow_logger = logging.getLogger(__name__)
    flow_logger.setLevel(logging.INFO)
    if not any(isinstance(h, PrefectHandler) for h in flow_logger.handlers):
        flow_logger.addHandler(handler)
    flow_logger.propagate = True

# Example task for loading configuration (optional, adjust as needed)
# @task(retries=0, cache_expiration=timedelta(seconds=0))
# def load_configuration(config_path: Optional[str] = None) -> AppConfig:
#     """
#     Load application configuration.
#     """
#     logger.info("Loading configuration")
#     # return load_config(config_path) # Replace with actual config loading if used
#     return {} # Placeholder

@task
def {{cookiecutter.project_slug}}_task(name: str = "world") -> str:
    """
    A generic example task for the flow.

    Args:
        name: A name to greet.

    Returns:
        A greeting message.
    """
    logger.info(f"Running the generic {{cookiecutter.project_slug}} task for '{name}'")
    # Replace with actual task logic
    result = f"Hello, {name} from the {{cookiecutter.project_slug}} task!"
    logger.info(f"Generic task finished with result: '{result}'")
    return result


@flow(name="{{ cookiecutter.project_name }}.{{ cookiecutter.project_slug }}_flow")
async def {{cookiecutter.project_slug}}_flow(config_path: Optional[str] = None) -> None:
    """
    Main generic flow orchestrating tasks.

    Args:
        config_path: Path to configuration file (optional).
    """
    configure_prefect_logging()
    logger.info("Starting {{ cookiecutter.project_slug }} flow")

    # Optional: Load configuration
    # config = load_configuration(config_path)
    # logger.info(f"Configuration loaded: {config}") # Adjust logging as needed

    # Example: Run the generic task
    try:
        task_result = {{cookiecutter.project_slug}}_task(name="{{cookiecutter.project_name}}")
        logger.info(f"Task completed with result: {task_result}")

    except Exception as e:
        logger.error(f"Flow failed during task execution: {e}")
        # Add more robust error handling if needed

    logger.info("{{ cookiecutter.project_slug | capitalize }} flow completed successfully")

# Example function to register flow schedule (optional)
# def register_flow_schedule():
#     """
#     Register the flow with a schedule (example).
#     """
#     # config = load_config() # Load config if schedule depends on it
#     schedule_interval_minutes = 15 # Example interval
#     schedule = Interval(
#         start_date=datetime.utcnow(),
#         interval=timedelta(minutes=schedule_interval_minutes)
#     )
#
#     # This requires interaction with a Prefect server/backend
#     # {{ cookiecutter.project_slug }}_flow.register(
#     #     project_name="{{cookiecutter.project_name}}", # Example project name
#     #     schedule=schedule
#     # )
#
#     logger.info(f"Flow registration setup for schedule: every {schedule_interval_minutes} minutes")

if __name__ == "__main__":
    # Example of running the flow manually
    {{cookiecutter.project_slug}}_flow()
</file>

<file path="{{cookiecutter.project_name}}/src/{{cookiecutter.project_slug}}/util/__init__.py">
"""Utility functions and classes."""
</file>

<file path="{{cookiecutter.project_name}}/src/{{cookiecutter.project_slug}}/util/llm.py">
"""
Anthropic LLM client for generating ideation content.
"""

import os
import logging
import time
from typing import Dict, Any, Optional, Tuple
import anthropic
from jinja2 import Template
from tenacity import retry, wait_exponential, stop_after_attempt
from abc import ABC, abstractmethod
from google import genai
from ..config import LLMConfig

# Set up logging
logger = logging.getLogger(__name__)

# Rate limiting configuration
# Format: (provider, model): (requests_per_window, window_seconds)
RATE_LIMITS: Dict[Tuple[str, str], Tuple[int, int]] = {
    ("gemini", "gemini-2.5-pro-exp-03-25"): (2, 60),  # 2 requests per minute
}

class LLMProvider(ABC):
    """Abstract base class for LLM providers."""
    
    @abstractmethod
    async def generate_response(self, prompt: str) -> str:
        """Generate a response from the LLM provider given a prompt.

        Args:
            prompt (str): The input prompt to send to the LLM.

        Returns:
            str: The response text from the LLM.
        """
        pass

class AnthropicProvider(LLMProvider):
    """Provider for Anthropic's Claude API."""
    
    def __init__(
        self, 
        api_key: str, 
        model: str = "claude-3-7-sonnet-latest", 
        max_tokens: int = 2000,
        temperature: float = 0.7
    ):
        """Initialize the Anthropic provider.

        Args:
            api_key (str): Anthropic API key.
            model (str): Model name (e.g., 'claude-3-sonnet-20240229').
            max_tokens (int): Maximum tokens in the response.
            temperature (float): Temperature for generation (0.0-1.0).
        """
        if not api_key:
            raise ValueError("Anthropic API key is required")
        
        self.client = anthropic.AsyncAnthropic(api_key=api_key)
        self.model = model
        self.max_tokens = max_tokens
        self.temperature = temperature
        self.request_timestamps = []
        logger.info(f"Anthropic provider initialized with model {model}")

    def _check_rate_limit(self) -> None:
        """Check and enforce rate limiting for the model.
        
        Raises:
            Exception: If rate limit is exceeded.
        """
        rate_limit = RATE_LIMITS.get(("anthropic", self.model))
        if not rate_limit:
            return
            
        requests_per_window, window_seconds = rate_limit
        current_time = time.time()
        
        # Remove timestamps older than the rate limit window
        self.request_timestamps = [ts for ts in self.request_timestamps 
                                 if current_time - ts < window_seconds]
        
        # Check if we've exceeded the rate limit
        if len(self.request_timestamps) >= requests_per_window:
            oldest_request = self.request_timestamps[0]
            wait_time = window_seconds - (current_time - oldest_request)
            if wait_time > 0:
                logger.warning(f"Rate limit reached for Anthropic model {self.model}. Waiting {wait_time:.2f} seconds.")
                time.sleep(wait_time)
                # Update timestamps after waiting
                self.request_timestamps = [ts for ts in self.request_timestamps 
                                         if current_time - ts < window_seconds]
        
        # Add current request timestamp
        self.request_timestamps.append(current_time)

    async def generate_response(self, prompt: str) -> str:
        """Generate a response using the Anthropic API.

        Args:
            prompt (str): The input prompt.

        Returns:
            str: The generated response text.
        """
        try:
            logger.info(f"Generating response from Anthropic model {self.model}")
            # Check and enforce rate limiting
            self._check_rate_limit()
            
            logger.info(f"Sending request to Anthropic API: model={self.model}, max_tokens={self.max_tokens}, temperature={self.temperature}")
            logger.debug(f"Prompt: {prompt[:100]}{'...' if len(prompt) > 100 else ''}")
            
            response = await self.client.messages.create(
                model=self.model,
                max_tokens=self.max_tokens,
                temperature=self.temperature,
                messages=[{"role": "user", "content": prompt}]
            )
            return response.content[0].text
        except Exception as e:
            logger.error(f"Error calling Anthropic API: {e}")
            raise

class GeminiProvider(LLMProvider):
    """Provider for Google's Gemini API."""
    
    def __init__(self, api_key: str, model: str = "gemini-2.0-flash-thinking-exp"):
        """Initialize the Gemini provider.

        Args:
            api_key (str): Gemini API key.
            model (str): Model name (e.g., 'gemini-2.0-flash-thinking-exp').
        """
        if not api_key:
            raise ValueError("Gemini API key is required")
        
        self.client = genai.Client(api_key=api_key, http_options={'api_version': 'v1alpha'})
        self.model = model
        self.request_timestamps = []
        logger.info(f"Gemini provider initialized with model {model}")

    def _check_rate_limit(self) -> None:
        """Check and enforce rate limiting for the model.
        
        Raises:
            Exception: If rate limit is exceeded.
        """
        rate_limit = RATE_LIMITS.get(("gemini", self.model))
        if not rate_limit:
            return
            
        requests_per_window, window_seconds = rate_limit
        current_time = time.time()
        
        # Remove timestamps older than the rate limit window
        self.request_timestamps = [ts for ts in self.request_timestamps 
                                 if current_time - ts < window_seconds]
        
        # Check if we've exceeded the rate limit
        if len(self.request_timestamps) >= requests_per_window:
            oldest_request = self.request_timestamps[0]
            wait_time = window_seconds - (current_time - oldest_request)
            if wait_time > 0:
                logger.warning(f"Rate limit reached for Gemini model {self.model}. Waiting {wait_time:.2f} seconds.")
                time.sleep(wait_time)
                # Update timestamps after waiting
                self.request_timestamps = [ts for ts in self.request_timestamps 
                                         if current_time - ts < window_seconds]
        
        # Add current request timestamp
        self.request_timestamps.append(current_time)

    async def generate_response(self, prompt: str) -> str:
        """Generate a response using the Gemini API.

        Args:
            prompt (str): The input prompt.

        Returns:
            str: The generated response text.
        """
        try:
            logger.info(f"Generating response from Gemini model {self.model}")
            # Check and enforce rate limiting
            self._check_rate_limit()
            
            logger.info(f"Sending request to Gemini API: model={self.model}")
            logger.debug(f"Prompt: {prompt[:100]}{'...' if len(prompt) > 100 else ''}")
            
            response = self.client.models.generate_content(model=self.model, contents=prompt)
            logger.info(f"Gemini generated response of length {len(response.text)}")
            return response.text
        except Exception as e:
            logger.error(f"Error calling Gemini API: {e}")
            raise

def create_llm_provider(llm_config: LLMConfig) -> LLMProvider:
    """Create an LLM provider instance based on configuration.

    Args:
        llm_config (LLMConfig): The LLM configuration specifying the provider and settings.

    Returns:
        LLMProvider: An instance of the selected LLM provider.

    Raises:
        ValueError: If the provider is unknown or required config is missing.
    """
    if llm_config.provider == "anthropic":
        if not llm_config.anthropic:
            raise ValueError("Anthropic config is required when provider is 'anthropic'")
        return AnthropicProvider(**llm_config.anthropic.dict())
    elif llm_config.provider == "gemini":
        if not llm_config.gemini:
            raise ValueError("Gemini config is required when provider is 'gemini'")
        return GeminiProvider(**llm_config.gemini.dict())
    else:
        raise ValueError(f"Unknown LLM provider: {llm_config.provider}")

class LLMClient:
    """Client for interacting with LLM providers."""
    
    def __init__(self, provider: LLMProvider):
        """Initialize LLM client with a provider.

        Args:
            provider (LLMProvider): The LLM provider instance to use.
        """
        self.provider = provider
        logger.info("LLM client initialized with provider")

    @retry(
        wait=wait_exponential(multiplier=1, max=10),
        stop=stop_after_attempt(3)
    )
    async def generate_ideation(self, task_content: str, repo_context: str, prompt_template_path: Optional[str] = None) -> str:
        """Generate ideation using the configured LLM provider.

        Args:
            task_content (str): Content of the task.
            repo_context (str): Repository context.
            prompt_template_path (Optional[str]): Path to Jinja2 template for prompt.

        Returns:
            str: Ideation output from the LLM provider.
        """
        logger.info(f"Generating ideation for task: '{task_content}'")

        # Render prompt from template or use default
        if prompt_template_path and os.path.exists(prompt_template_path):
            prompt = self._render_prompt(prompt_template_path, task_content, repo_context)
        else:
            prompt = f"""You are an AI development assistant helping to generate ideas for coding tasks.

Here is a task that needs ideation:
TASK: {task_content}

Here is context from the repository to help you understand the project:
REPOSITORY CONTEXT: 
{repo_context}

Please generate the following:
1. A clear understanding of what the task is asking for
2. 3-5 specific implementation ideas for this task
3. Potential challenges and how to address them
4. Suggested next steps

Focus on being practical and specific. Provide code examples where appropriate.
Make sure your ideas are directly relevant to the task and project context.
Be innovative but realistic given the constraints of the codebase and task requirements."""

        logger.debug(f"Using prompt: {prompt}")

        # Generate response using the provider
        response = await self.provider.generate_response(prompt)
        logger.info(f"Generated ideation of length {len(response)}")
        return response

    def _render_prompt(self, template_path: str, task_content: str, repo_context: str) -> str:
        """Render a prompt from a Jinja2 template.

        Args:
            template_path (str): Path to Jinja2 template.
            task_content (str): Content of the task.
            repo_context (str): Repository context.

        Returns:
            str: Rendered prompt string.

        Raises:
            Exception: If rendering fails.
        """
        try:
            logger.info(f"Rendering prompt template from {template_path}")
            with open(template_path, "r") as f:
                template_content = f.read()
            template = Template(template_content)
            return template.render(task=task_content, repo_context=repo_context)
        except Exception as e:
            logger.error(f"Error rendering prompt template: {e}")
            raise
</file>

<file path="{{cookiecutter.project_name}}/src/{{cookiecutter.project_slug}}/util/todoist.py">
"""
Todoist API client for fetching and updating tasks.
"""

from typing import List, Dict, Optional, Any, Tuple
import logging
import time
import re
import os
from tenacity import retry, wait_exponential, stop_after_attempt, retry_if_exception_type
from todoist_api_python.api import TodoistAPI
from todoist_api_python.models import Task, Project, Section
from requests.exceptions import RequestException as TodoistRequestError
from requests.exceptions import HTTPError

# Set up logging
logger = logging.getLogger(__name__)

# Constants
MAX_COMMENT_LENGTH = 14000

class TodoistClient:
    """Client for interacting with Todoist API."""
    
    def __init__(self, api_key: str):
        """
        Initialize Todoist client with API key.
        
        Args:
            api_key: Todoist API key
        """
        if not api_key:
            raise ValueError("Todoist API key is required")
        
        self.api = TodoistAPI(api_key)
        logger.info("Todoist client initialized")
    
    def _split_content_at_sections(self, content: str, max_length: int = MAX_COMMENT_LENGTH) -> List[str]:
        """
        Split content at markdown section boundaries while respecting max length.
        
        Args:
            content: The content to split
            max_length: Maximum length for each part
            
        Returns:
            List of content parts, each within max_length
        """
        logger.info(f"Splitting content of length {len(content)} at {max_length}")
        if len(content) <= max_length:
            return [content]
            
        # Find all markdown section headers (h1-h6)
        section_pattern = r'^(#{1,6}\s.+)$'
        sections = re.finditer(section_pattern, content, re.MULTILINE)
        
        # Convert to list of (position, header) tuples
        section_positions = [(m.start(), m.group(1)) for m in sections]
        
        if not section_positions:
            # If no sections found, split at max_length
            return [content[i:i + max_length] for i in range(0, len(content), max_length)]
            
        parts = []
        current_pos = 0
        
        logger.info(f"Found {len(section_positions)} sections")
        while current_pos < len(content):
            # Find the last section that fits within max_length
            last_valid_section = None
            for pos, header in section_positions:
                if pos < current_pos:  # Skip sections we've already processed
                    continue
                if pos - current_pos > max_length:
                    break
                last_valid_section = pos
                
            if last_valid_section is None:
                # If no section fits, split at max_length
                parts.append(content[current_pos:current_pos + max_length])
                current_pos += max_length
            else:
                # Split at the last valid section
                parts.append(content[current_pos:last_valid_section])
                current_pos = last_valid_section
                
            logger.info(f"Current position: {current_pos}, Content length: {len(content)}")
            
            # If we've processed all sections but still have content left
            if current_pos >= len(content):
                break
                
            # If we're at the end of the content
            if current_pos >= len(content) - 1:
                break
                
            # If we've processed all sections
            if all(pos < current_pos for pos, _ in section_positions):
                # Add any remaining content
                if current_pos < len(content):
                    parts.append(content[current_pos:])
                break
                
            # If we're stuck at the same position, force a split
            if current_pos == last_valid_section:
                parts.append(content[current_pos:current_pos + max_length])
                current_pos += max_length
                if current_pos >= len(content):
                    break
        
        logger.info(f"Split content into {len(parts)} parts")
        return parts

    @retry(
        retry=retry_if_exception_type(TodoistRequestError),
        wait=wait_exponential(multiplier=1, max=10),
        stop=stop_after_attempt(3)
    )
    def get_dev_project(self) -> Optional[Project]:
        """
        Get the dev project.
        
        Returns:
            Project object for dev project or None if not found
        """
        logger.info("Fetching dev project")
        projects = self.api.get_projects()
        
        for project in projects:
            if project.name == "dev":
                return project
        
        return None

    @retry(
        retry=retry_if_exception_type(TodoistRequestError),
        wait=wait_exponential(multiplier=1, max=10),
        stop=stop_after_attempt(3)
    )
    def get_sub_projects(self, parent_id: str) -> List[Project]:
        """
        Get all sub-projects under a parent project.
        
        Args:
            parent_id: ID of the parent project
            
        Returns:
            List of Project objects
        """
        logger.info(f"Fetching sub-projects for parent {parent_id}")
        all_projects = self.api.get_projects()
        return [p for p in all_projects if getattr(p, 'parent_id', None) == parent_id]

    @retry(
        retry=retry_if_exception_type(TodoistRequestError),
        wait=wait_exponential(multiplier=1, max=10),
        stop=stop_after_attempt(3)
    )
    def get_project_by_name(self, project_name: str) -> Project:
        """
        Get a project by name.
        
        Args:
            project_name: Name of the project
            
        Returns:
            Project object
            
        Raises:
            ValueError: If project not found
        """
        logger.info(f"Fetching project: {project_name}")
        projects = self.api.get_projects()
        
        for project in projects:
            if project.name == project_name:
                return project
        
        raise ValueError(f"Project '{project_name}' not found")
    
    @retry(
        retry=retry_if_exception_type(TodoistRequestError),
        wait=wait_exponential(multiplier=1, max=10),
        stop=stop_after_attempt(3)
    )
    def get_section_by_name(self, project_id: str, section_name: str) -> Optional[Section]:
        """
        Get a section by name within a project.
        
        Args:
            project_id: ID of the project
            section_name: Name of the section
            
        Returns:
            Section object or None if not found
        """
        logger.info(f"Fetching section '{section_name}' in project {project_id}")
        sections = self.api.get_sections(project_id=project_id)
        
        for section in sections:
            if section.name == section_name:
                return section
        
        return None
    
    @retry(
        retry=retry_if_exception_type(TodoistRequestError),
        wait=wait_exponential(multiplier=1, max=10),
        stop=stop_after_attempt(3)
    )
    def fetch_tasks(self, project_name: Optional[str] = None, section_name: Optional[str] = None, search_dev_subprojects: bool = True) -> List[Task]:
        """
        Fetch tasks from Todoist for a specific project and section.
        If search_dev_subprojects is True, it will search for tasks in the specified section
        across all sub-projects under the dev project.
        
        Args:
            project_name: Name of the project, or None if searching dev sub-projects
            section_name: Name of the section, or None for all sections
            search_dev_subprojects: Whether to search all sub-projects under dev
            
        Returns:
            List of Task objects
        """
        all_tasks = []
        
        if search_dev_subprojects:
            logger.info("Searching for tasks in dev sub-projects")
            dev_project = self.get_dev_project()
            if not dev_project:
                logger.warning("Dev project not found")
                return []
                
            sub_projects = self.get_sub_projects(dev_project.id)
            logger.info(f"Found {len(sub_projects)} sub-projects under dev")
            
            for project in sub_projects:
                if section_name:
                    section = self.get_section_by_name(project.id, section_name)
                    if section:
                        tasks = self.api.get_tasks(project_id=project.id, section_id=section.id)
                        all_tasks.extend(tasks)
                else:
                    tasks = self.api.get_tasks(project_id=project.id)
                    all_tasks.extend(tasks)
        else:
            if not project_name:
                raise ValueError("project_name is required when not searching dev sub-projects")
                
            project = self.get_project_by_name(project_name)
            if section_name:
                section = self.get_section_by_name(project.id, section_name)
                if section:
                    all_tasks = self.api.get_tasks(project_id=project.id, section_id=section.id)
                else:
                    logger.warning(f"Section '{section_name}' not found in project '{project_name}', fetching all tasks")
                    all_tasks = self.api.get_tasks(project_id=project.id)
            else:
                all_tasks = self.api.get_tasks(project_id=project.id)
        
        logger.info(f"Found {len(all_tasks)} tasks total")
        return all_tasks
    
    @retry(
        retry=retry_if_exception_type(TodoistRequestError),
        wait=wait_exponential(multiplier=1, max=10),
        stop=stop_after_attempt(3)
    )
    def fetch_non_ideated_tasks(self, project_name: str, section_name: Optional[str] = None, ideated_label: str = "ideated") -> List[Task]:
        """
        Fetch tasks that don't have the ideated label.
        
        Args:
            project_name: Name of the project
            section_name: Name of the section, or None for all sections
            ideated_label: Label that marks tasks as already ideated
            
        Returns:
            List of Task objects without the ideated label
        """
        tasks = self.fetch_tasks(project_name, section_name)
        
        # Filter out tasks that already have the ideated label
        non_ideated_tasks = [task for task in tasks if not any(label == ideated_label for label in task.labels)]
        
        logger.info(f"Found {len(non_ideated_tasks)} tasks without the '{ideated_label}' label")
        return non_ideated_tasks
    
    @retry(
        retry=retry_if_exception_type(TodoistRequestError),
        wait=wait_exponential(multiplier=1, max=10),
        stop=stop_after_attempt(3)
    )
    def update_task(self, task_id: str, **kwargs) -> Task:
        """
        Update a task with new attributes.
        
        Args:
            task_id: ID of the task to update
            **kwargs: Attributes to update (content, description, etc.)
            
        Returns:
            Updated Task object
        """
        logger.info(f"Updating task {task_id}")
        return self.api.update_task(task_id=task_id, **kwargs)
    
    @retry(
        retry=retry_if_exception_type(TodoistRequestError),
        wait=wait_exponential(multiplier=1, max=10),
        stop=stop_after_attempt(3)
    )
    def add_comment(self, task_id: str, content: str) -> List[Dict[str, Any]]:
        """
        Add a comment to a task. If content exceeds MAX_COMMENT_LENGTH,
        splits it into multiple comments at markdown section boundaries.
        
        Args:
            task_id: ID of the task
            content: Comment content
            
        Returns:
            List of comment dictionaries
            
        Raises:
            HTTPError: If the API request fails
        """
        logger.info(f"Adding comment(s) to task {task_id}")
        
        # Split content if needed
        content_parts = self._split_content_at_sections(content)
        logger.info(f"Split content into {len(content_parts)} parts")
        comments = []
        
        try:
            for i, part in enumerate(content_parts, 1):
                if len(content_parts) > 1:
                    # Add part number to header if multiple parts
                    if part.startswith('# '):
                        part = f"# Part {i}\n\n{part}"
                    else:
                        part = f"# Part {i}\n\n{part}"
                
                logger.info(f"Adding comment {i} of {len(content_parts)}")
                comment = self.api.add_comment(task_id=task_id, content=part)
                comments.append(comment)
                
                # Add small delay between comments to avoid rate limiting
                if i < len(content_parts):
                    time.sleep(1)
                    
            return comments
            
        except HTTPError as e:
            # Log the error details including the payload
            error_msg = f"Failed to add comment to task {task_id}. Status code: {e.response.status_code}"
            if hasattr(e.response, 'text'):
                error_msg += f"\nResponse text: {e.response.text}"
            logger.error(error_msg)
            logger.error(f"Comment content that caused error (length: {len(content)}):\n{content}")
            raise
    
    @retry(
        retry=retry_if_exception_type(TodoistRequestError),
        wait=wait_exponential(multiplier=1, max=10),
        stop=stop_after_attempt(3)
    )
    def update_task_with_ideation(self, task_id: str, ideation_result: str, ideated_label: str = "ideated") -> None:
        """
        Update a task with ideation results:
        1. Add ideation to description
        2. Add comment with ideation
        3. Add ideated label
        
        Args:
            task_id: ID of the task
            ideation_result: Result from LLM ideation
            ideated_label: Label to add to the task
        """
        logger.info(f"Updating task {task_id} with ideation results")
        
        # Get current task to get labels
        task = self.api.get_task(task_id=task_id)
        
        # Add ideated label if not already present
        labels = task.labels.copy() if task.labels else []
        if ideated_label not in labels:
            labels.append(ideated_label)
        
        # Update task with ideation
        self.update_task(
            task_id=task_id,
            labels=labels
        )
        
        # Add comment with ideation
        self.add_comment(task_id=task_id, content=f"# Ideation Results\n\n{ideation_result}")
        
        # Small delay to avoid rate limiting
        time.sleep(1)

    @retry(
        retry=retry_if_exception_type(TodoistRequestError),
        wait=wait_exponential(multiplier=1, max=10),
        stop=stop_after_attempt(3)
    )
    def update_task_with_error(self, task_id: str, error_type: str, error_message: str) -> None:
        """
        Update a task with error information:
        1. Add error comment
        2. Do not add ideated label
        
        Args:
            task_id: ID of the task
            error_type: Type of error that occurred
            error_message: Detailed error message
        """
        logger.info(f"Updating task {task_id} with error information")
        
        # Add comment with error details
        error_comment = f"""# Error During Ideation

**Error Type:** {error_type}
**Error Message:** {error_message}

The ideation process failed after multiple retries. Please try again later or contact support if the issue persists."""
        
        self.add_comment(task_id=task_id, content=error_comment)
        
        # Small delay to avoid rate limiting
        time.sleep(1)

def main():
    """Test the add_comment functionality."""
    # Set up logging
    logging.basicConfig(level=logging.INFO)
    
    # Get API key from environment
    api_key = os.getenv("TODOIST_API_KEY")
    if not api_key:
        raise ValueError("TODOIST_API_KEY environment variable is required")
    
    # Initialize client
    client = TodoistClient(api_key)
    
    # Read test content
    with open("test.txt", "r") as f:
        test_content = f.read()
    
    # Test task ID
    task_id = "9006602349"
    
    try:
        # Add comment
        logger.info(f"Testing add_comment with content length: {len(test_content)}")
        comments = client.add_comment(task_id, test_content)
        logger.info(f"Successfully added {len(comments)} comments")
        
        # Log each comment's length
        for i, comment in enumerate(comments, 1):
            logger.info(f"Comment {i} length: {len(comment.content)}")
            
    except Exception as e:
        logger.error(f"Error during testing: {str(e)}")
        raise

if __name__ == "__main__":
    main()
</file>

<file path="{{cookiecutter.project_name}}/src/{{cookiecutter.project_slug}}/__init__.py">
"""Top-level package for {{ cookiecutter.project_name }}."""

__version__ = '{{ cookiecutter.version }}'
</file>

<file path="{{cookiecutter.project_name}}/src/{{cookiecutter.project_slug}}/{{cookiecutter.project_slug}}.py">
"""Main module."""
</file>

<file path="{{cookiecutter.project_name}}/src/{{cookiecutter.project_slug}}/config.py">
"""
Configuration management for {{ cookiecutter.project_name }}.
"""

import os
import yaml
from pathlib import Path
from typing import Dict, Any, Optional
from pydantic import BaseModel, Field, ValidationError
import logging
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()

# Set up logging
logger = logging.getLogger(__name__)

class TodoistConfig(BaseModel):
    """Todoist API configuration."""
    api_key: Optional[str] = Field(None, description="Todoist API key") # Made optional
    project_name: str = Field("MyProject", description="Default Todoist project name")
    section_name: str = Field("Ideas", description="Default Todoist section name")
    ideated_label: str = Field("ideated", description="Label to add to ideated tasks")

class GitHubConfig(BaseModel):
    """GitHub configuration."""
    username: Optional[str] = Field(None, description="GitHub username") # Made optional
    token: Optional[str] = Field(None, description="GitHub API token")
    repo_path: str = Field("./repos", description="Path to store repositories")

class AnthropicConfig(BaseModel):
    """Anthropic-specific configuration."""
    api_key: Optional[str] = Field(None, description="Anthropic API key") # Made optional
    model: str = Field("claude-3-sonnet-20240229", description="Model to use for ideation")
    max_tokens: int = Field(2000, description="Maximum tokens in response")
    temperature: float = Field(0.7, description="Model temperature (0.0-1.0)")

class GeminiConfig(BaseModel):
    """Gemini-specific configuration."""
    api_key: Optional[str] = Field(None, description="Gemini API key") # Made optional
    model: str = Field("gemini-2.0-flash-thinking-exp", description="Model to use for ideation")

class LLMConfig(BaseModel):
    """LLM provider configuration."""
    provider: Optional[str] = Field(None, description="LLM provider to use ('anthropic' or 'gemini')") # Made optional
    anthropic: Optional[AnthropicConfig] = Field(None, description="Anthropic configuration if provider is 'anthropic'")
    gemini: Optional[GeminiConfig] = Field(None, description="Gemini configuration if provider is 'gemini'")

class PrefectConfig(BaseModel):
    """Prefect configuration."""
    # Use cookiecutter variables for defaults
    project_name: str = Field("{{ cookiecutter.project_slug }}", description="Prefect project name")
    flow_name: str = Field("{{ cookiecutter.project_name }} Flow", description="Flow name") 
    schedule_interval_minutes: int = Field(30, description="Schedule interval in minutes")

class AppConfig(BaseModel):
    """Main application configuration."""
    # Make Todoist, GitHub, LLM optional
    todoist: Optional[TodoistConfig] = None
    github: Optional[GitHubConfig] = None
    llm: Optional[LLMConfig] = None 
    prefect: PrefectConfig # Prefect remains required
    prompt_template_path: str = Field(
        "templates/ideation_prompt.jinja2", 
        description="Path to the Jinja2 template for LLM prompts"
    )

def _get_env_var(key: str, default: Any = None) -> Any:
    """Helper to get environment variable, returning default if not set or empty."""
    value = os.getenv(key)
    return value if value else default

def _load_section_config(section_key: str, model: type[BaseModel], config_data: Dict[str, Any], env_prefix: str) -> Optional[BaseModel]:
    """Loads configuration for a specific section, overriding with env vars."""
    section_data = config_data.get(section_key, {})
    env_overrides = {}
    
    # Dynamically get fields from the model and check corresponding env vars
    for field_name in model.model_fields.keys():
        # Handle nested models like anthropic/gemini within llm
        if isinstance(model.model_fields[field_name].annotation, type) and issubclass(model.model_fields[field_name].annotation, BaseModel):
             nested_model = model.model_fields[field_name].annotation
             nested_env_prefix = f"{env_prefix}_{field_name.upper()}"
             nested_data = section_data.get(field_name, {})
             
             nested_env_overrides = {}
             for nested_field_name in nested_model.model_fields.keys():
                 nested_env_var = f"{nested_env_prefix}_{nested_field_name.upper()}"
                 env_val = _get_env_var(nested_env_var)
                 if env_val is not None:
                     # Attempt type conversion for nested fields based on model type hints
                     field_type = nested_model.model_fields[nested_field_name].annotation
                     try:
                         if field_type == int:
                             env_val = int(env_val)
                         elif field_type == float:
                             env_val = float(env_val)
                     except ValueError:
                          logger.warning(f"Could not convert env var {nested_env_var} value '{env_val}' to type {field_type}. Using default.")
                          env_val = None # Reset to None if conversion fails
                 
                 if env_val is not None: # Only add if env var was set and conversion succeeded (or wasn't needed)
                    nested_env_overrides[nested_field_name] = env_val

             # Merge env overrides into nested data from file
             nested_data.update(nested_env_overrides)
             if nested_data: # Only add nested config if it has data
                 env_overrides[field_name] = nested_data

        else: # Handle simple fields
            env_var = f"{env_prefix}_{field_name.upper()}"
            env_val = _get_env_var(env_var)
            if env_val is not None:
                 # Attempt type conversion based on model type hints
                 field_type = model.model_fields[field_name].annotation
                 # Handle Optional types
                 if hasattr(field_type, '__origin__') and field_type.__origin__ is Optional:
                      # Get the actual type argument from Optional[T] -> T
                      field_type = field_type.__args__[0]

                 try:
                     if field_type == int:
                         env_val = int(env_val)
                     elif field_type == float:
                          env_val = float(env_val)
                 except ValueError:
                     logger.warning(f"Could not convert env var {env_var} value '{env_val}' to type {field_type}. Using default.")
                     env_val = None # Reset to None if conversion fails

            if env_val is not None: # Only add if env var was set and conversion succeeded (or wasn't needed)
                 env_overrides[field_name] = env_val

    # Merge environment overrides into the data loaded from the file
    final_data = {**section_data, **env_overrides}
    
    # If after merging, there's no data for the section, return None
    if not final_data:
        return None
        
    # Validate and create the model instance
    try:
        return model(**final_data)
    except ValidationError as e:
        logger.error(f"Configuration validation error for section '{section_key}': {e}")
        # For optional sections, return None if validation fails due to missing required fields
        # that weren't provided by file or env vars (e.g. api_key if it were mandatory)
        # Check if errors are due to missing fields that are now optional at the AppConfig level.
        # A more robust check might be needed depending on specific validation rules.
        # For now, let's return None if *any* validation error occurs for an optional section.
        # Prefect is mandatory, so errors there should likely propagate or halt.
        if section_key in ["todoist", "github", "llm"]: 
             logger.warning(f"Optional configuration section '{section_key}' failed validation, treating as disabled.")
             return None
        else: # Re-raise for mandatory sections like Prefect if validation fails
             raise e

def load_config(config_path: Optional[str] = None) -> AppConfig:
    """
    Load configuration from a YAML file and environment variables.
    Environment variables take precedence over the config file.
    Optional sections (Todoist, GitHub, LLM) are loaded only if configuration
    is found in the file or environment variables. Prefect config is required.

    Args:
        config_path: Path to the config.yaml file, or None to use default

    Returns:
        AppConfig object with all configuration settings
    """
    # Default config path is in the project root
    if config_path is None:
        config_path = os.path.join(os.path.dirname(__file__), "..", "..", "config.yaml")
    
    config_path = Path(config_path)
    
    config_data = {}
    # Load config from file if it exists
    if config_path.exists():
        logger.info(f"Loading configuration from {config_path}")
        try:
            with open(config_path, "r") as f:
                loaded_yaml = yaml.safe_load(f)
                if loaded_yaml: # Ensure file is not empty
                     config_data = loaded_yaml
        except yaml.YAMLError as e:
             logger.error(f"Error parsing config file {config_path}: {e}")
        except Exception as e:
             logger.error(f"Error reading config file {config_path}: {e}")
    else:
        logger.info(f"Config file {config_path} not found. Loading from environment variables and defaults.")

    # --- Load individual sections ---
    
    # Optional Sections: Load only if data exists in file or env vars
    todoist_config = _load_section_config("todoist", TodoistConfig, config_data, "TODOIST")
    github_config = _load_section_config("github", GitHubConfig, config_data, "GITHUB")
    llm_config = _load_section_config("llm", LLMConfig, config_data, "LLM")

    # Required Section: Prefect (Load with specific defaults from model)
    prefect_file_data = config_data.get("prefect", {})
    prefect_env_overrides = {}
    prefect_defaults = {
        "project_name": "{{ cookiecutter.project_slug }}",
        "flow_name": "{{ cookiecutter.project_name }} Flow",
        "schedule_interval_minutes": 30,
    }
    for field_name, default_value in prefect_defaults.items():
        env_var = f"PREFECT_{field_name.upper()}"
        # Special case for schedule interval env var name
        if field_name == "schedule_interval_minutes":
             env_var = "PREFECT_SCHEDULE_INTERVAL"
             
        env_val = _get_env_var(env_var)
        if env_val is not None:
             try:
                 # Ensure correct type for interval
                 if field_name == "schedule_interval_minutes":
                      prefect_env_overrides[field_name] = int(env_val)
                 else:
                      prefect_env_overrides[field_name] = env_val
             except ValueError:
                 logger.warning(f"Could not convert env var {env_var} value '{env_val}' to expected type. Using default.")
        elif field_name not in prefect_file_data: # Use default if not in file and no env var
             prefect_env_overrides[field_name] = default_value
             
    # Merge file data and env overrides for Prefect
    final_prefect_data = {**prefect_file_data, **prefect_env_overrides}
    # Ensure defaults are present if not overridden
    for field_name, default_value in prefect_defaults.items():
         if field_name not in final_prefect_data:
              final_prefect_data[field_name] = default_value
              
    try:
        prefect_config = PrefectConfig(**final_prefect_data)
    except ValidationError as e:
        logger.critical(f"FATAL: Required Prefect configuration failed validation: {e}")
        raise # Halt execution if Prefect config is invalid


    # --- Load general settings ---
    prompt_template_path = _get_env_var(
        "PROMPT_TEMPLATE_PATH", 
        config_data.get("prompt_template_path", "templates/ideation_prompt.jinja2") # Default from original code
    )

    # Create the final AppConfig object
    try:
         app_config = AppConfig(
             todoist=todoist_config,
             github=github_config,
             llm=llm_config,
             prefect=prefect_config,
             prompt_template_path=prompt_template_path
         )
         return app_config
    except ValidationError as e:
         logger.critical(f"FATAL: Final application configuration failed validation: {e}")
         raise # Halt execution if final config is invalid

# Example usage (optional, for testing)
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    # Example: Set some env vars for testing
    # os.environ["TODOIST_API_KEY"] = "test_todoist_key_from_env"
    # os.environ["GITHUB_USERNAME"] = "test_github_user_from_env"
    # os.environ["LLM_PROVIDER"] = "gemini"
    # os.environ["GEMINI_API_KEY"] = "test_gemini_key_from_env"
    # os.environ["PREFECT_PROJECT_NAME"] = "my-{{cookiecutter.project_slug}}-env"
    
    print("Loading configuration...")
    try:
        config = load_config()
        print("\nLoaded Configuration:")
        print(config.model_dump_json(indent=2))

        # Example checks for optional configs
        if config.todoist:
            print("\nTodoist Config Loaded:")
            print(f"  API Key Set: {'Yes' if config.todoist.api_key else 'No'}")
            print(f"  Project: {config.todoist.project_name}")
        else:
            print("\nTodoist Config: Not Loaded/Disabled")

        if config.github:
            print("\nGitHub Config Loaded:")
            print(f"  Username: {config.github.username or 'Not Set'}")
            print(f"  Token Set: {'Yes' if config.github.token else 'No'}")
        else:
             print("\nGitHub Config: Not Loaded/Disabled")

        if config.llm:
            print("\nLLM Config Loaded:")
            print(f"  Provider: {config.llm.provider or 'Not Set'}")
            if config.llm.provider == "anthropic" and config.llm.anthropic:
                print(f"  Anthropic Key Set: {'Yes' if config.llm.anthropic.api_key else 'No'}")
            elif config.llm.provider == "gemini" and config.llm.gemini:
                 print(f"  Gemini Key Set: {'Yes' if config.llm.gemini.api_key else 'No'}")
        else:
            print("\nLLM Config: Not Loaded/Disabled")
            
        print("\nPrefect Config (Required):")
        print(f"  Project Name: {config.prefect.project_name}")
        print(f"  Flow Name: {config.prefect.flow_name}")
        print(f"  Interval (min): {config.prefect.schedule_interval_minutes}")
        
        print(f"\nPrompt Template Path: {config.prompt_template_path}")

    except Exception as e:
        print(f"\nError loading or validating configuration: {e}")
</file>

<file path="{{cookiecutter.project_name}}/tests/__init__.py">
"""Unit test package for {{ cookiecutter.project_slug }}."""
</file>

<file path="{{cookiecutter.project_name}}/tests/test_{{cookiecutter.project_slug}}.py">
#!/usr/bin/env python

"""Tests for `{{ cookiecutter.project_slug }}` package."""

{% if cookiecutter.use_pytest == 'y' -%}
import pytest
{% else %}
import unittest
{%- endif %}

from {{ cookiecutter.project_slug }} import {{ cookiecutter.project_slug }}
{%- if cookiecutter.use_pytest == 'y' %}


@pytest.fixture
def response():
    """Sample pytest fixture.

    See more at: http://doc.pytest.org/en/latest/fixture.html
    """
    # import requests
    # return requests.get('https://github.com/audreyr/cookiecutter-pypackage')


def test_content(response):
    """Sample pytest test function with the pytest fixture as an argument."""
    # from bs4 import BeautifulSoup
    # assert 'GitHub' in BeautifulSoup(response.content).title.string
{%- else %}


class Test{{ cookiecutter.project_slug|title }}(unittest.TestCase):
    """Tests for `{{ cookiecutter.project_slug }}` package."""

    def setUp(self):
        """Set up test fixtures, if any."""

    def tearDown(self):
        """Tear down test fixtures, if any."""

    def test_000_something(self):
        """Test something."""
{%- endif %}
</file>

<file path="{{cookiecutter.project_name}}/.gitignore">
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
env/
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
.hypothesis/
.pytest_cache/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
target/

# Jupyter Notebook
.ipynb_checkpoints

# Dask worker cache
dask-worker-space/

# pyenv
.python-version

# celery beat schedule file
celerybeat-schedule

# SageMath parsed files
*.sage.py

# dotenv
.env

# virtualenv
.venv
venv/
ENV/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/

# IDE settings
.vscode/
.idea/
</file>

<file path="{{cookiecutter.project_name}}/pyproject.toml">
[project]
name = "{{cookiecutter.project_slug}}"
version = "{{cookiecutter.version}}"
description = "{{cookiecutter.description}}"
readme = "README.md"
requires-python = ">=3.12"
classifiers = [
    "Programming Language :: Python :: 3",
    "Operating System :: OS Independent",
]

dependencies = [
    "pydantic",
    "anthropic",
    "python-dotenv",
    "httpx",
    "rich",
    "prefect",
]


[project.optional-dependencies]
dev = [
    "pytest",
    "coverage",
    "ruff",
    "mypy"
]

[project.urls]

bugs = "https://github.com/{{cookiecutter.__gh_slug}}/issues"
changelog = "https://github.com/{{cookiecutter.__gh_slug}}/blob/master/changelog.md"
homepage = "https://github.com/{{cookiecutter.__gh_slug}}"


[project.scripts]
{{cookiecutter.project_slug}} = "{{cookiecutter.project_slug}}.cli:app"


# Mypy
# ----

[tool.mypy]
files = "."
python_version = "3.12"


strict = true
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
disallow_incomplete_defs = true
warn_unreachable = true
warn_no_return = true

[[tool.mypy.overrides]]
# Don't require test functions to include types
module = "tests.*"
allow_untyped_defs = true
disable_error_code = "attr-defined"
</file>

<file path="{{cookiecutter.project_name}}/README.md">
{% for _ in cookiecutter.project_name %}={% endfor %}
{{ cookiecutter.project_name }}
{% for _ in cookiecutter.project_name %}={% endfor %}

{{ cookiecutter.description }}
</file>

<file path="{{cookiecutter.project_name}}/scripts/run_{{cookiecutter.project_slug}}.py">
#!/usr/bin/env python3
"""
Script to run the default {{cookiecutter.project_slug}} flow.
"""

import os
import traceback
import sys
import logging
import asyncio
from pathlib import Path

# Add the src directory to the Python path
src_dir = Path(__file__).parent.parent / "src"
sys.path.append(str(src_dir))

from {{cookiecutter.project_slug}}.flows import {{cookiecutter.project_slug}}_flow
from {{cookiecutter.project_slug}}.config import load_config
from prefect import get_run_logger

# Set up logging
logging.basicConfig(
    level=logging.DEBUG,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)

# Remove Prefect-specific logging configuration
# logging.getLogger("prefect").setLevel(logging.DEBUG)
# logging.getLogger("prefect.flows").setLevel(logging.DEBUG)
# logging.getLogger("prefect.tasks").setLevel(logging.DEBUG)

logger = logging.getLogger(__name__)

def main():
    """Run the {{cookiecutter.project_slug}} flow."""
    try:
        # Load configuration
        config = load_config()
        
        # Log configuration status
        logger.info("Configuration loaded successfully")
        
        # Run the flow
        asyncio.run({{cookiecutter.project_slug}}_flow())
        
    except Exception as e:
        print(f"Error running {{cookiecutter.project_slug}} flow: {str(e)}")
        stacktrace = traceback.format_exc()
        logger.error(f"Error running {{cookiecutter.project_slug}} flow: {str(e)}")
        logger.error(f"Stack trace: {stacktrace}")
        sys.exit(1)

if __name__ == "__main__":
    main()
</file>

<file path="cookiecutter.json">
{
  "project_name": "{{ cookiecutter.project_name }}",
  "project_slug": "{{ cookiecutter.project_slug }}",
  "description": "{{ cookiecutter.description }}",
  "github_username": "{{ cookiecutter.github_username }}",
  "version": "0.1.0",
  "use_pytest": "y",
  "create_author_file": "y",
  "__gh_slug": "{{ cookiecutter.github_username }}/{{ cookiecutter.project_name }}"
}
</file>

<file path="test_config.json">
{
      "default_context": {
          "project_name": "simple-calculator",
          "project_slug": "calc",
          "github_username": "lherron",
          "description": "A description of my awesome package"
      }                                                                                                                                                                  
  }
</file>

<file path="Makefile">
BAKE_OPTIONS=--no-input

help:
	@echo "bake 	Generate project using defaults"
	@echo "help 	Show this help"
	@echo "test 	Run the tests"
	@echo "replay 	Replay last cookiecutter run and watch for changes"
	@echo "watch 	Generate project using defaults and watch for changes"
	

bake:  # Generate project using defaults
	cookiecutter --config-file test_config.json $(BAKE_OPTIONS) . --overwrite-if-exists

watch: bake
	watchmedo shell-command -p '*.*' -c 'make bake -e BAKE_OPTIONS=$(BAKE_OPTIONS)' -W -R -D \{{cookiecutter.project_name}}/

replay: BAKE_OPTIONS=--replay
replay: watch
	;

test:
	pytest
</file>

<file path=".gitignore">
# Byte-compiled / optimized / DLL files
simple-calculator/
my-awesome-package/
my_awesome_package/
__pycache__/
*.py[cod]
*$py.class

# OSX useful to ignore
*.DS_Store
.AppleDouble
.LSOverride

# Thumbnails
._*

# Files that might appear in the root of a volume
.DocumentRevisions-V100
.fseventsd
.Spotlight-V100
.TemporaryItems
.Trashes
.VolumeIcon.icns
.com.apple.timemachine.donotpresent

# Directories potentially created on remote AFP share
.AppleDB
.AppleDesktop
Network Trash Folder
Temporary Items
.apdisk

# C extensions
*.so

# Distribution / packaging
.Python
.env
env/
venv/
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
*.egg-info/
.installed.cfg
*.egg

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*,cover
.hypothesis/
.pytest_cache/

# Translations
*.mo
*.pot

# Django stuff:
*.log

# Sphinx documentation
docs/_build/

# IntelliJ Idea family of suites
.idea
*.iml
## File-based project format:
*.ipr
*.iws
## mpeltonen/sbt-idea plugin
.idea_modules/

# PyBuilder
target/

# Cookiecutter
output/
python_boilerplate/
cookiecutter-pypackage-env/

# IDE settings
.vscode/
</file>

</files>
